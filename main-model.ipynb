{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7573343,"sourceType":"datasetVersion","datasetId":4408965},{"sourceId":9940774,"sourceType":"datasetVersion","datasetId":6111916},{"sourceId":171464,"sourceType":"modelInstanceVersion","modelInstanceId":145930,"modelId":168500}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-19T06:58:02.255638Z","iopub.execute_input":"2024-11-19T06:58:02.255962Z","iopub.status.idle":"2024-11-19T06:58:38.810865Z","shell.execute_reply.started":"2024-11-19T06:58:02.255929Z","shell.execute_reply":"2024-11-19T06:58:38.809649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# final v3\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Subset\nfrom torchvision import datasets, transforms, models\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Dataset Path - Update to Kaggle's working directory\ndataset_dir = \"/kaggle/input/alzheimers-disease-neuro-imaging/AugmentedAlzheimerDataset\"\n\n# Ensure dataset exists\nif not os.path.exists(dataset_dir):\n    raise FileNotFoundError(f\"Dataset not found at {dataset_dir}. Please upload it to Kaggle's working directory.\")\n\n# Data Transformations\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n])\n\n# Valid file check function\ndef is_valid_file(filename):\n    valid_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff', '.webp', '.gif')\n    return filename.lower().endswith(valid_extensions)\n\n# Load Dataset\ndataset = datasets.ImageFolder(root=dataset_dir, transform=transform, is_valid_file=is_valid_file)\n\n# Split Dataset\ntrain_val_idx, test_idx = train_test_split(range(len(dataset)), test_size=0.15, random_state=42)\ntrain_idx, val_idx = train_test_split(train_val_idx, test_size=0.15, random_state=42)\n\ntrain_dataset = Subset(dataset, train_idx)\nval_dataset = Subset(dataset, val_idx)\ntest_dataset = Subset(dataset, test_idx)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n\n# Model Definition\nclass AlzheimerNet(nn.Module):\n    def __init__(self, num_classes=4):\n        super(AlzheimerNet, self).__init__()\n        self.resnet = models.resnet18(pretrained=True)\n        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, num_classes)\n\n    def forward(self, x):\n        return self.resnet(x)\n\n# Initialize Model\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = AlzheimerNet(num_classes=4).to(device)\n\n# Loss and Optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-11-19T10:12:39.388692Z","iopub.execute_input":"2024-11-19T10:12:39.388964Z","iopub.status.idle":"2024-11-19T10:13:38.682674Z","shell.execute_reply.started":"2024-11-19T10:12:39.388938Z","shell.execute_reply":"2024-11-19T10:13:38.681960Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|██████████| 44.7M/44.7M [00:00<00:00, 131MB/s] \n","output_type":"stream"}]},{"cell_type":"code","source":"# Training Loop\ndef train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n    for epoch in range(num_epochs):\n        model.train()\n        running_loss, correct, total = 0.0, 0, 0\n\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n        train_loss = running_loss / len(train_loader)\n        train_accuracy = 100 * correct / total\n        print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.2f}%\")\n\n        validate_model(model, val_loader, criterion)\n\n# Validation Loop\ndef validate_model(model, val_loader, criterion):\n    model.eval()\n    val_loss, correct, total = 0.0, 0, 0\n    with torch.no_grad():\n        for images, labels in val_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    avg_loss = val_loss / len(val_loader)\n    accuracy = 100 * correct / total\n    print(f\"Validation Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n\n# Test Model\ndef test_model(model, test_loader, criterion):\n    model.eval()\n    test_loss, correct, total = 0.0, 0, 0\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            test_loss += loss.item()\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    avg_loss = test_loss / len(test_loader)\n    accuracy = 100 * correct / total\n    print(f\"Test Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n\n# Train, Validate, and Test the Model\ntrain_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10)\ntest_model(model, test_loader, criterion)\n\n# Save Model\ntorch.save(model.state_dict(), \"/kaggle/working/alzheimers_cnn_model.pth\")\nprint(\"Model saved to kaggle\")\n\n# Reload and Evaluate Model\nmodel.load_state_dict(torch.load(\"/kaggle/working/alzheimers_cnn_model.pth\"))\nmodel.eval()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualisation\nimport torch\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nimport seaborn as sns\n\n# --- Setup Configuration ---\nmodel_path = \"/kaggle/input/cnn-model/pytorch/default/1/alzheimers_cnn_model.pth\"  # Path to the saved model\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Ensure device is defined\n\n# --- Load the Pre-trained Model ---\ntry:\n    # Load model weights only and recreate the model architecture manually (if required)\n    # If your model architecture is already defined in the codebase, load its state_dict\n    model = AlzheimerNet(num_classes=4).to(device)\n    model.load_state_dict(torch.load(model_path, map_location=device))  # Load weights\n    model = model.to(device)\n    model.eval()\n    print(\"Model loaded successfully.\")\nexcept Exception as e:\n    print(f\"Error loading model: {e}\")\n    exit()\n\n# --- Load and Preprocess Data ---\ntry:\n    # Ensure test_loader is defined; it should be a DataLoader object from PyTorch\n    data_iter = iter(test_loader)\n    images, labels = next(data_iter)\n    images, labels = images.to(device), labels.to(device)\nexcept Exception as e:\n    print(f\"Error fetching data: {e}\")\n    exit()\n\n# --- Make Predictions ---\nwith torch.no_grad():  # Disable gradient calculation\n    outputs = model(images)\n    _, predicted = torch.max(outputs, 1)\n\n# --- Convert Predictions and Labels ---\ntrue_labels_np = labels.cpu().numpy()\npredicted_np = predicted.cpu().numpy()\n\n# --- Save Predictions as CSV ---\ndata = pd.DataFrame({\n    \"True Labels\": true_labels_np,\n    \"Predicted Labels\": predicted_np\n})\ncsv_file_name = \"predictions.csv\"\ndata.to_csv(csv_file_name, index=False)\nprint(f\"Predictions saved as '{csv_file_name}'\")\n\n# --- Label Distributions ---\ntrue_labels, true_counts = np.unique(true_labels_np, return_counts=True)\npred_labels, pred_counts = np.unique(predicted_np, return_counts=True)\n\n# Pie Chart\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\nax1.pie(true_counts, labels=true_labels, autopct='%1.1f%%', startangle=90)\nax1.set_title('Distribution of True Labels')\nax2.pie(pred_counts, labels=pred_labels, autopct='%1.1f%%', startangle=90)\nax2.set_title('Distribution of Predicted Labels')\nplt.savefig(\"label_distribution_pie.png\")\nprint(\"Pie chart saved as 'label_distribution_pie.png'\")\nplt.show()\n\n# Bar Chart\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\nax1.bar(true_labels, true_counts, color='blue', alpha=0.7, label='True')\nax1.set_title('Distribution of True Labels')\nax1.set_xlabel('Labels')\nax1.set_ylabel('Count')\nax2.bar(pred_labels, pred_counts, color='orange', alpha=0.7, label='Predicted')\nax2.set_title('Distribution of Predicted Labels')\nax2.set_xlabel('Labels')\nax2.set_ylabel('Count')\nplt.savefig(\"label_distribution_bar.png\")\nprint(\"Bar chart saved as 'label_distribution_bar.png'\")\nplt.show()\n\n# --- Confusion Matrix ---\ncm = confusion_matrix(true_labels_np, predicted_np)\n\n# Confusion Matrix Display\nfig, ax = plt.subplots(figsize=(8, 8))\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[f\"Class {i}\" for i in range(len(true_labels))])\ndisp.plot(ax=ax, cmap=\"Blues\", values_format=\"d\")\nplt.title(\"Confusion Matrix\")\nplt.savefig(\"confusion_matrix.png\")\nprint(\"Confusion matrix saved as 'confusion_matrix.png'\")\nplt.show()\n\n# Heatmap for Confusion Matrix\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap=\"coolwarm\", xticklabels=true_labels, yticklabels=true_labels)\nplt.title(\"Confusion Matrix Heatmap\")\nplt.xlabel(\"Predicted Labels\")\nplt.ylabel(\"True Labels\")\nplt.savefig(\"confusion_matrix_heatmap.png\")\nprint(\"Heatmap saved as 'confusion_matrix_heatmap.png'\")\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-11-19T10:30:07.672693Z","iopub.execute_input":"2024-11-19T10:30:07.673422Z","iopub.status.idle":"2024-11-19T10:30:10.246148Z","shell.execute_reply.started":"2024-11-19T10:30:07.673365Z","shell.execute_reply":"2024-11-19T10:30:10.244908Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Error loading model: name 'AlzheimerNet' is not defined\nError fetching data: name 'test_loader' is not defined\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 38\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# --- Make Predictions ---\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():  \u001b[38;5;66;03m# Disable gradient calculation\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m(images)\n\u001b[1;32m     39\u001b[0m     _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# --- Convert Predictions and Labels ---\u001b[39;00m\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"],"ename":"NameError","evalue":"name 'model' is not defined","output_type":"error"}]}]}